{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c179d540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       file_path             class\n",
      "0    Data\\fold5\\100032-3-0-0.wav          dog_bark\n",
      "1  Data\\fold5\\100263-2-0-117.wav  children_playing\n",
      "2  Data\\fold5\\100263-2-0-121.wav  children_playing\n",
      "3  Data\\fold5\\100263-2-0-126.wav  children_playing\n",
      "4  Data\\fold5\\100263-2-0-137.wav  children_playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Audio_Classification\\.venv\\Lib\\site-packages\\librosa\\feature\\spectral.py:2148: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8732, 128) (8732,)\n",
      "[-1.3482255  -1.2236692  -1.1316347  -1.1461596  -1.178558   -1.1745125\n",
      " -1.0340447  -0.93703234 -0.7997523  -0.59453374 -0.47595215 -0.4441112\n",
      " -0.38117942 -0.2386911  -0.29449016 -0.20423783 -0.18983157 -0.24527268\n",
      " -0.4072699  -0.4512159  -0.43714538 -0.45558703 -0.30265516 -0.13684435\n",
      " -0.22802036 -0.4483584  -0.45787716 -0.4088175  -0.37859172 -0.44224262\n",
      " -0.53664947 -0.6146636  -0.67115396 -0.7385174  -0.814543   -0.9101011\n",
      " -1.0466732  -1.0670856  -0.92826647 -1.0721225  -1.2127682  -1.2910459\n",
      " -1.2607192  -1.2695026  -1.2778567  -1.3437096  -1.3886501  -1.2127593\n",
      " -1.2135909  -1.1892092  -1.2079809  -1.2362734  -1.2802215  -1.390651\n",
      " -1.4704983  -1.5087192  -1.5625389  -1.6282246  -1.6469471  -1.6556369\n",
      " -1.6926061  -1.694156   -1.6973214  -1.74441     0.6683605   0.73290193\n",
      "  0.7833929   0.7505707   0.745637    0.8098202   0.81915736  0.8794411\n",
      "  0.9675095   0.99065393  1.00603     1.0596918   1.1045706   1.0740318\n",
      "  0.9988428   0.96384865  0.9906596   0.98305035  0.97135466  0.9851057\n",
      "  1.003665    0.95869297  0.9755044   0.98554623  1.0146058   1.0120614\n",
      "  0.98068243  1.0088763   1.0409899   1.0240008   1.006542    0.98744196\n",
      "  1.0217825   0.9934017   1.0105697   0.99424064  0.96821725  0.9598533\n",
      "  0.9664874   0.9588093   0.940049    0.9387209   0.9519981   0.96345586\n",
      "  0.9512284   0.945256    0.94332194  1.0293897   1.0167015   1.0228431\n",
      "  1.0293353   1.0270331   1.0192299   0.9728575   0.9287938   0.906916\n",
      "  0.86654985  0.8121355   0.803689    0.796141    0.76450753  0.78118247\n",
      "  0.7817937   0.72256297]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"Data\")\n",
    "CSV_PATH = Path(\"UrbanSound8K.csv\")\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Create full path to each wav file\n",
    "df[\"file_path\"] = df.apply(\n",
    "    lambda row: DATA_DIR / f\"fold{row['fold']}\" / row[\"slice_file_name\"],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(df[[\"file_path\", \"class\"]].head())\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_mfcc(file_path, n_mfcc=40):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)  # fixed-size vector\n",
    "    return mfcc_mean\n",
    "\n",
    "def extract_mel(file_path, n_mels=64):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels =n_mels , n_fft=1024 , hop_length=512)\n",
    "    mel_db = librosa.power_to_db(mel , ref=np.max)\n",
    "    mel_mean = np.mean(mel_db, axis=1)  # fixed-size vector\n",
    "    mel_std = np.std(mel_db, axis=1)\n",
    "    features = np.concatenate([mel_mean, mel_std])\n",
    "    features = (features - np.mean(features)) / np.std(features)\n",
    "    # mel_db = (mel_db - mel_mean) / mel_std\n",
    "\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    try:\n",
    "        features = extract_mel(row[\"file_path\"])\n",
    "        X.append(features)\n",
    "        y.append(row[\"classID\"])  # numeric label\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {row['file_path']}: {e}\")\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "print(X[0])\n",
    "print(y[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc6be2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>Data\\fold5\\100032-3-0-0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.5</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>Data\\fold5\\100263-2-0-117.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>Data\\fold5\\100263-2-0-121.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>Data\\fold5\\100263-2-0-126.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>Data\\fold5\\100263-2-0-137.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
       "\n",
       "              class                      file_path  \n",
       "0          dog_bark    Data\\fold5\\100032-3-0-0.wav  \n",
       "1  children_playing  Data\\fold5\\100263-2-0-117.wav  \n",
       "2  children_playing  Data\\fold5\\100263-2-0-121.wav  \n",
       "3  children_playing  Data\\fold5\\100263-2-0-126.wav  \n",
       "4  children_playing  Data\\fold5\\100263-2-0-137.wav  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "364fd799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Audio_Classification\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3681 - loss: 1.9300 - val_accuracy: 0.3405 - val_loss: 1.8397\n",
      "Epoch 2/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4981 - loss: 1.4706 - val_accuracy: 0.5665 - val_loss: 1.3069\n",
      "Epoch 3/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5528 - loss: 1.3132 - val_accuracy: 0.6080 - val_loss: 1.1468\n",
      "Epoch 4/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5764 - loss: 1.2422 - val_accuracy: 0.4979 - val_loss: 1.5014\n",
      "Epoch 5/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6102 - loss: 1.1439 - val_accuracy: 0.6638 - val_loss: 1.0163\n",
      "Epoch 6/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6316 - loss: 1.0846 - val_accuracy: 0.5408 - val_loss: 1.3053\n",
      "Epoch 7/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6440 - loss: 1.0482 - val_accuracy: 0.5665 - val_loss: 1.2797\n",
      "Epoch 8/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6723 - loss: 0.9749 - val_accuracy: 0.5408 - val_loss: 1.2972\n",
      "Epoch 9/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6656 - loss: 0.9799 - val_accuracy: 0.6409 - val_loss: 1.0339\n",
      "Epoch 10/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6767 - loss: 0.9536 - val_accuracy: 0.6409 - val_loss: 1.1354\n",
      "Epoch 11/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6955 - loss: 0.9249 - val_accuracy: 0.5565 - val_loss: 1.3841\n",
      "Epoch 12/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6944 - loss: 0.9008 - val_accuracy: 0.6881 - val_loss: 0.9514\n",
      "Epoch 13/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7014 - loss: 0.8808 - val_accuracy: 0.6509 - val_loss: 0.9775\n",
      "Epoch 14/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7084 - loss: 0.8754 - val_accuracy: 0.6710 - val_loss: 1.0015\n",
      "Epoch 15/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7200 - loss: 0.8429 - val_accuracy: 0.6924 - val_loss: 0.9113\n",
      "Epoch 16/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7167 - loss: 0.8556 - val_accuracy: 0.7468 - val_loss: 0.7285\n",
      "Epoch 17/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7199 - loss: 0.8258 - val_accuracy: 0.6080 - val_loss: 1.2763\n",
      "Epoch 18/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7200 - loss: 0.8213 - val_accuracy: 0.6438 - val_loss: 1.0588\n",
      "Epoch 19/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7294 - loss: 0.7967 - val_accuracy: 0.7482 - val_loss: 0.7880\n",
      "Epoch 20/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7359 - loss: 0.7957 - val_accuracy: 0.6037 - val_loss: 1.3024\n",
      "Epoch 21/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7356 - loss: 0.7902 - val_accuracy: 0.7368 - val_loss: 0.7564\n",
      "Epoch 22/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7381 - loss: 0.7699 - val_accuracy: 0.7182 - val_loss: 0.7980\n",
      "Epoch 23/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7479 - loss: 0.7683 - val_accuracy: 0.7282 - val_loss: 0.7720\n",
      "Epoch 24/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7409 - loss: 0.7543 - val_accuracy: 0.6767 - val_loss: 0.9023\n",
      "Epoch 25/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7428 - loss: 0.7686 - val_accuracy: 0.6967 - val_loss: 0.8511\n",
      "Epoch 26/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7439 - loss: 0.7617 - val_accuracy: 0.7053 - val_loss: 0.8383\n",
      "Epoch 27/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7552 - loss: 0.7333 - val_accuracy: 0.6681 - val_loss: 0.9286\n",
      "Epoch 28/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7572 - loss: 0.7287 - val_accuracy: 0.7840 - val_loss: 0.5840\n",
      "Epoch 29/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7423 - loss: 0.7528 - val_accuracy: 0.6910 - val_loss: 0.8572\n",
      "Epoch 30/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7552 - loss: 0.7406 - val_accuracy: 0.7110 - val_loss: 0.7688\n",
      "Epoch 31/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7669 - loss: 0.7095 - val_accuracy: 0.7926 - val_loss: 0.5882\n",
      "Epoch 32/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7577 - loss: 0.7141 - val_accuracy: 0.6810 - val_loss: 0.9088\n",
      "Epoch 33/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7599 - loss: 0.7203 - val_accuracy: 0.5594 - val_loss: 1.4172\n",
      "Epoch 34/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7623 - loss: 0.7096 - val_accuracy: 0.7053 - val_loss: 0.8564\n",
      "Epoch 35/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7661 - loss: 0.7018 - val_accuracy: 0.8097 - val_loss: 0.5714\n",
      "Epoch 36/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7606 - loss: 0.7098 - val_accuracy: 0.7339 - val_loss: 0.7559\n",
      "Epoch 37/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7687 - loss: 0.6961 - val_accuracy: 0.8155 - val_loss: 0.5527\n",
      "Epoch 38/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7679 - loss: 0.6803 - val_accuracy: 0.8054 - val_loss: 0.5523\n",
      "Epoch 39/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7690 - loss: 0.6836 - val_accuracy: 0.7325 - val_loss: 0.7622\n",
      "Epoch 40/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7712 - loss: 0.6684 - val_accuracy: 0.6567 - val_loss: 1.0654\n",
      "Epoch 41/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7638 - loss: 0.6890 - val_accuracy: 0.7396 - val_loss: 0.7783\n",
      "Epoch 42/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7700 - loss: 0.6782 - val_accuracy: 0.7797 - val_loss: 0.6636\n",
      "Epoch 43/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7782 - loss: 0.6758 - val_accuracy: 0.6695 - val_loss: 0.9659\n",
      "Epoch 44/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7677 - loss: 0.6944 - val_accuracy: 0.7768 - val_loss: 0.6484\n",
      "Epoch 45/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7719 - loss: 0.6825 - val_accuracy: 0.7825 - val_loss: 0.6609\n",
      "Epoch 46/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7701 - loss: 0.6726 - val_accuracy: 0.8240 - val_loss: 0.5420\n",
      "Epoch 47/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7736 - loss: 0.6747 - val_accuracy: 0.7511 - val_loss: 0.7168\n",
      "Epoch 48/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7736 - loss: 0.6639 - val_accuracy: 0.7883 - val_loss: 0.6272\n",
      "Epoch 49/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7763 - loss: 0.6752 - val_accuracy: 0.7783 - val_loss: 0.6991\n",
      "Epoch 50/50\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7852 - loss: 0.6424 - val_accuracy: 0.8269 - val_loss: 0.5398\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7871 - loss: 0.6022\n",
      "Test Accuracy: 0.7870635390281677\n",
      "Test Loss: 0.6022323966026306\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y   # IMPORTANT for class balance\n",
    ")\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential([\n",
    "\n",
    "    # Input layer\n",
    "    Dense(256, activation='relu', input_shape=(128,)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    # Hidden layer 1\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    # Hidden layer 2\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    # Output layer\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    verbose=1,\n",
    "    # callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_acc )\n",
    "print(\"Test Loss:\", test_loss )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57e5d885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95       200\n",
      "           1       0.96      0.80      0.87        86\n",
      "           2       0.76      0.84      0.80       200\n",
      "           3       0.95      0.82      0.88       200\n",
      "           4       0.90      0.90      0.90       200\n",
      "           5       0.95      0.94      0.95       200\n",
      "           6       0.91      0.92      0.91        75\n",
      "           7       0.94      0.94      0.94       200\n",
      "           8       0.94      0.94      0.94       186\n",
      "           9       0.78      0.86      0.82       200\n",
      "\n",
      "    accuracy                           0.89      1747\n",
      "   macro avg       0.90      0.89      0.90      1747\n",
      "weighted avg       0.90      0.89      0.90      1747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=10,\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94daa2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['audio_classifier_xgb.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, \"audio_classifier_xgb.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9db746aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model = joblib.load(\"audio_classifier_xgb.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0614fa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {\n",
    "    0: \"air_conditioner\",\n",
    "    1: \"car_horn\",\n",
    "    2: \"children_playing\",\n",
    "    3: \"dog_bark\",\n",
    "    4: \"drilling\",\n",
    "    5: \"engine_idling\",\n",
    "    6: \"gun_shot\",\n",
    "    7: \"jackhammer\",\n",
    "    8: \"siren\",\n",
    "    9: \"street_music\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d842fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_audio(file_path, model):\n",
    "    features = extract_mel(file_path)   # SAME function as training\n",
    "\n",
    "    features = features.reshape(1, -1)  # (1, 128)\n",
    "\n",
    "    probs = model.predict_proba(features)\n",
    "    pred_id = probs.argmax(axis=1)[0]\n",
    "    pred_class = class_map[pred_id]\n",
    "    return pred_class\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df17a6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'siren'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"74726-8-0-3.wav\"\n",
    "predict_audio(file_path=file_path , model=model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
